{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **First Approach**"
      ],
      "metadata": {
        "id": "3FoLXSDOL-Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install PyPDF2\n",
        "!pip install openai\n",
        "!pip install --upgrade --force-reinstltall langchain"
      ],
      "metadata": {
        "id": "6N5aZ13uUmjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKMvwxOmR8xt",
        "outputId": "0282d082-7d7b-4f94-dd40-8a0429fdd80e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "import PyPDF2\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "import faiss\n",
        "import openai"
      ],
      "metadata": {
        "id": "KvvbOkDWTJhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "29TwxP38SimP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_api_key(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            api_key = file.read().strip()  # Read the API key and strip any leading/trailing whitespace\n",
        "            return api_key\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: File not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"/content/drive/MyDrive/Data/api_key.txt\"\n",
        "    api_key = load_api_key(file_path)\n",
        "    if api_key:\n",
        "        print(\"API Key:\", api_key)\n",
        "    else:\n",
        "        print(\"Failed to load API Key.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDC1DrxYm9rO",
        "outputId": "4582dba8-73bd-4e1d-d56c-add18fc57b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key: {\\rtf1\\ansi\\ansicpg1252\\cocoartf2709\n",
            "\\cocoatextscaling0\\cocoaplatform0{\\fonttbl\\f0\\fmodern\\fcharset0 Courier;}\n",
            "{\\colortbl;\\red255\\green255\\blue255;\\red194\\green126\\blue101;\\red23\\green23\\blue23;}\n",
            "{\\*\\expandedcolortbl;;\\cssrgb\\c80784\\c56863\\c47059;\\cssrgb\\c11765\\c11765\\c11765;}\n",
            "\\paperw11900\\paperh16840\\margl1440\\margr1440\\vieww11520\\viewh8400\\viewkind0\n",
            "\\deftab720\n",
            "\\pard\\pardeftab720\\partightenfactor0\n",
            "\n",
            "\\f0\\fs28 \\cf2 \\cb3 \\expnd0\\expndtw0\\kerning0\n",
            "\\outl0\\strokewidth0 \\strokec2 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}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import PyPDF2\n",
        "import faiss\n",
        "\n",
        "class PyPDFLoader:\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "\n",
        "    def load_text(self):\n",
        "        text = \"\"\n",
        "        with open(self.path, \"rb\") as f:\n",
        "            reader = PyPDF2.PdfReader(f)\n",
        "            num_pages = len(reader.pages)\n",
        "            for page_num in range(num_pages):\n",
        "                page = reader.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "\n",
        "# Example usage:\n",
        "pdf_path = \"/content/drive/MyDrive/Data/Drug-Safety-Priorities-Report.pdf\"\n",
        "pdf_loader = PyPDFLoader(path=pdf_path)\n",
        "\n",
        "# Define embedding model\n",
        "embedding_model = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# Define vector store\n",
        "vector_store = FAISS()\n",
        "\n",
        "# Define chain\n",
        "chain = LLMChain(\n",
        "    loader=pdf_loader,\n",
        "    embedding_model=embedding_model,\n",
        "    vector_store=vector_store,\n",
        "    language_model=\"openai/gpt-3.5-turbo\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=64,\n",
        "    k=3,  # number of relevant passages to retrieve\n",
        ")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "query = \" What is the Orange Book, and what information does it contain?\"\n",
        "response = chain(query)\n",
        "\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "aKB2wrz9SP2U",
        "outputId": "da37a4ac-7aff-49e9-87f9-143d3479d6c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "FAISS.__init__() missing 4 required positional arguments: 'embedding_function', 'index', 'docstore', and 'index_to_docstore_id'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-07bd3e6b28cd>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Define vector store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mvector_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Define chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: FAISS.__init__() missing 4 required positional arguments: 'embedding_function', 'index', 'docstore', and 'index_to_docstore_id'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "import faiss\n",
        "\n",
        "class PyPDFLoader:\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "\n",
        "    def load_text(self):\n",
        "        text = \"\"\n",
        "        with open(self.path, \"rb\") as f:\n",
        "            reader = PyPDF2.PdfReader(f)\n",
        "            num_pages = len(reader.pages)\n",
        "            for page_num in range(num_pages):\n",
        "                page = reader.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "\n",
        "# Example usage:\n",
        "pdf_path = \"/content/drive/MyDrive/Data/Drug-Safety-Priorities-Report.pdf\"\n",
        "pdf_loader = PyPDFLoader(path=pdf_path)\n",
        "\n",
        "# Define embedding model\n",
        "embedding_model = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# Define FAISS index\n",
        "index = faiss.IndexFlatL2()\n",
        "\n",
        "# Load text using the custom loader\n",
        "pdf_text = pdf_loader.load_text()\n",
        "\n",
        "# Encode PDF text using the embedding model\n",
        "doc_embeddings =  embedding_model.encode_text(pdf_text)\n",
        "\n",
        "# Add embeddings to FAISS index\n",
        "index.add(doc_embeddings)\n",
        "\n",
        "# Define FAISS vector store\n",
        "vector_store = FAISS(embedding_model.embed, index, doc_embeddings, {})  # Pass an empty dictionary for index_to_docstore_id\n",
        "\n",
        "# Define chain\n",
        "chain = LLMChain(\n",
        "    loader=pdf_loader,\n",
        "    embedding_model=embedding_model,\n",
        "    vector_store=vector_store,\n",
        "    language_model=\"openai/gpt-3.5-turbo\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=64,\n",
        "    k=3,  # number of relevant passages to retrieve\n",
        ")\n",
        "\n",
        "# Example usage\n",
        "query = \"What is the primary risk management tool for prescription medications according to the FDA?\"\n",
        "response = chain(query)\n",
        "\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "-BrlyidRUkNj",
        "outputId": "6c1f92d7-601f-4bb8-f1da-308e2dcde452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'OpenAIEmbeddings' object has no attribute 'encode_text'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-c07d80dc45b0>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Encode PDF text using the embedding model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdoc_embeddings\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Add embeddings to FAISS index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'OpenAIEmbeddings' object has no attribute 'encode_text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifBTBWypyVV7",
        "outputId": "4d70e61e-14d2-46ad-a7ad-251122282233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import encode_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "6UROt0bDdUdi",
        "outputId": "a0d97d80-cd6a-427d-8f0a-107bf0e1a9f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'encode_text'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-b3341ab80cc0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mencode_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'encode_text'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_pdf_text(path):\n",
        "    text = \"\"\n",
        "    with open(path, \"rb\") as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        num_pages = len(reader.pages)\n",
        "        for page_num in range(num_pages):\n",
        "            page = reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Example usage:\n",
        "pdf_path = \"/content/drive/MyDrive/Data/Drug-Safety-Priorities-Report.pdf\"\n",
        "pdf_loader = load_pdf_text(pdf_path)\n",
        "\n",
        "# Define embedding model\n",
        "embedding_model = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# Encode PDF text using the embedding model\n",
        "doc_embeddings = embedding_model.embedding(pdf_loader)  # Corrected line\n",
        "\n",
        "# Define FAISS index\n",
        "index = faiss.IndexFlatL2()\n",
        "index.add(doc_embeddings)\n",
        "\n",
        "# Define FAISS vector store\n",
        "vector_store = faiss.VectorStore(embedding_model.embedding, index, doc_embeddings)\n",
        "\n",
        "# Define chain\n",
        "chain = LLMChain(\n",
        "    loader=pdf_loader,\n",
        "    embedding_model=embedding_model,\n",
        "    vector_store=vector_store,\n",
        "    language_model=\"openai/gpt-3.5-turbo\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=64,\n",
        "    k=3,  # number of relevant passages to retrieve\n",
        ")\n",
        "\n",
        "# Example usage\n",
        "query = \"What is the primary risk management tool for prescription medications according to the FDA?\"\n",
        "response = chain(query)\n",
        "\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "V0A3oagL0q39",
        "outputId": "f501cfae-e2ae-4ade-ff3a-8e5e9a08167d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'OpenAIEmbeddings' object has no attribute 'embedding'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c774649e62f8>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Encode PDF text using the embedding model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdoc_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_loader\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Corrected line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Define FAISS index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'OpenAIEmbeddings' object has no attribute 'embedding'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "cnF1BmbTOUVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.12"
      ],
      "metadata": {
        "id": "FypivK9xOi_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Second approach**"
      ],
      "metadata": {
        "id": "aqnY_HViHbD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer"
      ],
      "metadata": {
        "id": "rF3JnSt5H3D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six"
      ],
      "metadata": {
        "id": "ivL0xllqIJQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install whoosh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFxCo1QbITk4",
        "outputId": "19a1fb2d-7075-44de-e1ef-a353af441651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting whoosh\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/468.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/468.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: whoosh\n",
            "Successfully installed whoosh-2.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain --upgrade"
      ],
      "metadata": {
        "id": "rGPi2AJRJtAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langchain.llms import OpenAI\n",
        "#from langchain.chains import RetrieverGenerator\n",
        "#from langchain.retrievers import SimpleRetriever"
      ],
      "metadata": {
        "id": "5xHEDA__I0hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RetrieverGenerator:\n",
        "    def __init__(self, retriever, generator):\n",
        "        self.retriever = retriever\n",
        "        self.generator = generator\n",
        "\n",
        "    def __call__(self, query):\n",
        "        # Retrieve relevant documents\n",
        "        relevant_docs = self.retriever(query)\n",
        "\n",
        "        # Generate response using the retrieved documents\n",
        "        response = self.generator(relevant_docs, query)\n",
        "\n",
        "        return response\n",
        "\n",
        "# Define your OpenAI API key\n",
        "openai.api_key = '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'\n",
        "\n",
        "# Initialize the OpenAI model\n",
        "openai_llm = openai.Completion.create(model=\"openai/gpt-3.5-turbo\")  # Choose the appropriate model\n",
        "\n",
        "# Example text data - replace with your actual data retrieval logic\n",
        "documents = [\n",
        "    {\"id\": \"doc1\", \"text\": \"Content of document 1.\"},\n",
        "    # Add more documents as needed\n",
        "]\n",
        "\n",
        "# Setup a simple retriever - replace this with your actual retriever implementation\n",
        "def simple_retriever(query):\n",
        "    # Example implementation: return all documents for now\n",
        "    return documents\n",
        "\n",
        "# Example query\n",
        "query = \"What is the primary risk management tool for prescription medications according to the FDA?\"\n",
        "\n",
        "# Execute the RetrieverGenerator chain\n",
        "response = RetrieverGenerator(retriever=simple_retriever, generator=openai_llm)(query)\n",
        "\n",
        "print(\"Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "8fT9MnlBI8_J",
        "outputId": "4c9f48d3-ee26-4c35-cb3a-739dedf51903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "APIRemovedInV1",
          "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-da7cc4272cee>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Initialize the OpenAI model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mopenai_llm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"openai/gpt-3.5-turbo\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Choose the appropriate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Example text data - replace with your actual data retrieval logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vh772cm4Lp9V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}